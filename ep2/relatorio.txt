MAC5742 - Relatório EP2
=======================

1. Alunos
---------

Ana Martinazzo (7209231)
Daniel Sakuma (5619562)


2. Conteúdo do diretório
------------------------
.
|-- relatorio.txt           - este arquivo
|-- reduction_cuda.cu       - implementação de redução usando CUDA
|-- reduction_cuda.h
|-- reduction_seq.cu        - implementação de redução sequencial
|-- reduction_seq.h
|-- functions.c             - funções auxiliares
|-- functions.h
|-- main.c                  - o programa de redução de matrizes
`-- Makefile


3. Como compilar e rodar
------------------------

Para compilar e executar o programa:

  $ ./make
  $ ./main <caminho_lista_matrizes>

Para compilar e executar os teste automatizados:

  $ ./make test
  $ ./test

Para compilar e executar os testes de performance:

  $ ./make test_performance
  $ ./test_performance

Para gerar uma lista de matrizes:

  $ ./make generate_matrix_list
  ./generate_matrix <qtd_matrizes> <caminho_lista_matrizes>


4. Descrição do problema/solução
--------------------------------

Neste exercício-programa, foi desenvolvido um programa em CUDA (versão 9) C/C++ para realizar uma
operação de redução de um conjunto de matrizes. A redução é uma abordagem de divisão e conquista,
na qual o problema é particionado e resolvido em partes, que depois são combinadas para encontrar
a solução final. Aqui, fizemos a redução das matrizes a fim de encontrar os mínimos.

O programa recebe como entrada um arquivo .txt contendo n matrizes de tamanho 3 x 3 (equivalente
a vetores unidimensionais de tamanho 9). É alocada uma matriz de tamanho 9 x n para receber os
valores de entrada. Em cada linha i, são inseridos os elementos da posição i das n matrizes. Assim,
o problema se torna a redução de 9 vetores de tamanho n, que resulta num único vetor de tamanho 9
contendo os valores mínimos finais.

O mínimo de cada vetor pode ser encontrado com uma busca em árvore, comparando elementos dois a
dois e retornando o mínimo parcial entre eles. Para evitar divergência de branch, o mínimo entre
dois inteiros não-negativos x e y pode ser computado com 0.5(abs(x+y) - abs(x-y)). A cada iteração
da busca, a quantidade de elementos é reduzida pela metade, até que reste um único elemento, o
mínimo global. Esta abordagem é intrinsicamente paralelizável: para um vetor de tamanho n, podem
ser disparadas n/2 threads em paralelo.

Tendo o problema modelado, é necessário então estudar um pouco da arquitetura das GPUs da NVIDIA.
As threads dentro da GPU ficam organizadas em blocos. Cada bloco tem uma memória compartilhada
própria (que não é acessada pelos demais blocos) e pode disparar até 1024 threads, porém a prática
mais comum e que costuma desempenhar melhor é usar 256 threads. Adotamos essa quantidade - ela
permite um bom desempenho sem causar muito overhead de criação de threads. Assim, se um vetor tem
tamanho maior que 256, é necessário particioná-lo e reduzi-lo em mais de um bloco de forma
independente. O kernel de redução é inicializado com um grid de 9 blocos na direção x e
ceil(n/256) blocos na direção y, onde n é a dimensão dos vetores (quantidade de matrizes). Cada
bloco retorna um mínimo parcial e o kernel é chamado recursivamente na CPU. Como CUDA não tem
sincronização global, essa recursão funciona como uma barreira de sincronização entre os blocos.


5. Testes automatizados
-----------------------

Foram implementados testes automatizados para comparação dos resultados do algoritmo de redução
implementado em CUDA e da redução sequencial processada na CPU. Os testes focam em cobrir casos
de fronteira, tanto do número de threads, quanto de blocos.

Além disso, foi implementado um teste para comparar a performance entre o processamento na GPU
e CPU. Os testes começam com 500k matrizes e dobram a cada testes até um máximo de 16M. A ideia
foi buscar a partir de qual momento é mais vantajosa a utilização da GPU.


6. Resultados
-------------

Executamos o teste automatizado em dois modelos de GPU, a GeForce GTX Titan X e a
Tesla K40c. Em todos os casos os valores obtidos na redução na GPU foram os mesmos
dos obtidos na CPU.


Para os testes de performance, utilizamos uma máquina com a GPU Tesla K40c e o processador
Intel Core i7-4770. Abaixo segue o output da execução dos testes:

Teste: Redução de 500k matrizes
Tempo Cuda: 2338156 us
Tempo Sequencial: 423987 us
A implementação Sequencial foi mais rápida em: 1914169 us

Teste: Redução de 1M matrizes
Tempo Cuda: 861562 us
Tempo Sequencial: 847149 us
A implementação Sequencial foi mais rápida em: 14413 us

Teste: Redução de 2M matrizes
Tempo Cuda: 1724705 us
Tempo Sequencial: 1692169 us
A implementação Sequencial foi mais rápida em: 32536 us

Teste: Redução de 4M matrizes
Tempo Cuda: 3443721 us
Tempo Sequencial: 3371158 us
A implementação Sequencial foi mais rápida em: 72563 us

Teste: Redução de 8M matrizes
Tempo Cuda: 6856060 us
Tempo Sequencial: 6754169 us
A implementação Sequencial foi mais rápida em: 101891 us

Teste: Redução de 16M matrizes
Tempo Cuda: 13899346 us
Tempo Sequencial: 13470023 us
A implementação Sequencial foi mais rápida em: 429323 us


7. Conclusões
-------------

A maior dificuldade neste exercício-programa foi entender a arquitetura da GPU e
como executar os blocos de código operam. Além disso, erros no kernel podem passar
despercebidos, uma vez que alguns erros não são notificados pela GPU, e o processamento
é finalizado executando a computação errada.

Talvez, devido a implementação, não houve ganhos em utilizar a GPU. Na lógica que utilizada,
para cada vetor de tamanho n, inicializamos n threads. Com algumas alterações no código,
a redução poderia ser resolvido com n/2 threads.

Outra melhoria seria ter o mínimo computado com 0.5(abs(x+y) - abs(x-y)), que eita a divergência
de branch.

Um outro possível teste, seria deixar de  utilizar o cudaMallocManaged, que facilita o
desenvolvimento utilizando o Unified Memory, e passar a gerenciar a memória manualmente.
