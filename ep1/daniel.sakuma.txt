MAC5742 - Relatório EP1
=======================

1. Aluno
--------

Daniel Sakuma
N USP: 5619562


2. Conteúdo do diretório
------------------------
.
|-- daniel.sakuma.txt       - este arquivo
|-- generate_matrix.c       - gera matriz A e matrix B
|-- main.c                  - o programa de multiplicação de matriz
|-- Makefile
|-- openmp_multiply.c       - implementação de multiplicação utilizando OpenMP
|-- openmp_multiply.h
|-- pthread_multiply.c      - implementação de multiplicação utilizando pthreads
|-- pthread_multiply.h
|-- sequential_multiply.c   - implementação de multiplicação sequencial
|-- sequential_multiply.h
|-- functions.c             - funções auxiliares
|-- functions.h
`-- utils
    `-- ascii-histogram.js  - gerador de histogramas em ascii.


3. Como compilar e rodar
------------------------

Para compilar e executar o programa:

  $ ./make
  $ ./main <implementação> <caminho_matr_A> <caminho_matr_B> <caminho_matr_C>

Para gerar a matriz de testes:

  $ ./make generate_matrix
  ./generate_matrix <n_linhas_matr_A> <n_cols_matr_A> <n_linhas_matr_B> <n_cols_matr_B>

Para rodar o utilitário de histograma

  $ node utils/ascii-histogram.js


4. Descrição da solução
-----------------------

A ideia desse programa é implementar, de maneira mais eficiente possível, o
algoritmo para a multiplicação entre duas matrizes. Nesse programa foram
utilizadas duas bibliotecas de paralelização, o OpenMP e o Pthreads.

O OpenMP permite paralelizar programas escritos em C, C++ e Fortran através de
anotações no código, que guiam o compilador para acrescentar simultaneidade
aos programas. O OpenMP utiliza a base do modelo de execução fork-join.

O Pthreads é um padrão que define uma interface para criação e manipulação
de threads. Ou seja, é uma interface padronizada para utilizar versões
proprietárias de implementação de threads em hardwares diferentes. Normalmente,
bibliotecas  que implementam o padrão de POSIX threads são  chamadas de Pthreads.

Foi implementado um algoritmo utilizando o OpenMP (o), que utiliza o #pragma opm parallel
para paralelizar o loop mais externo. Usando essa delcaração, porções do loop for
são delegadas para diferentes threads.

Também há a implementação usando Pthreads (p) que executa a multiplicação dividindo
o procesamento em três threads. O algoritmos foi desenvolvido para que o calculo
da multiplicação se divida entre as threads igualmente.

Por fim, há uma implementação sequencial (s), que utiliza o algoritmo mais básico de
multiplicação de matrizes, apenas para efeito de comparação.

Tentei fazer a utilização das instruções instrinsics Intel, mas não consegui
terminar a tempo.

5. Resultados
-------------

Para comparar a performance dos algoritmos paralelos em relação ao algoritmo
sequencial, foi feita a multiplicação de uma matriz 1500x1500.

Tempos obtidos em segundos:

sequential | ============================================================ | 22.112
    openMP | ===================================                          | 12.887
  pthreads | ====================================                         | 13.441


6. Conclusões
-------------

Mesmo com poucas alterações no código sequencial existente, a paralelização com o
OpenMP teve uma performance ligeiramente melhor em comparação à implementação
com Pthreads.
